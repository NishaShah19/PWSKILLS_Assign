{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fd6169",
   "metadata": {},
   "source": [
    "# Assignment Ensemble Techniques And Its Types-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff999372",
   "metadata": {},
   "source": [
    "#### Q1. What is an ensemble technique in machine learning?\n",
    "- ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. It combines low performing classifiers (also called as weak learners or base learner) and combine individual model prediction for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc218ec",
   "metadata": {},
   "source": [
    "#### Q2. Why are ensemble techniques used in machine learning?\n",
    "- In learning models, noise, variance, and bias are the major sources of error. The ensemble methods in machine learning help minimize these error-causing factors, thereby ensuring the accuracy and stability of machine learning (ML) algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e73e3",
   "metadata": {},
   "source": [
    "#### Q3. What is bagging?\n",
    "- Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once. After several data samples are generated, these weak models are then trained independently, and depending on the type of task—regression or classification, for example—the average or majority of those predictions yield a more accurate estimate.\n",
    "- Bootstrap Aggregating, also known as bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It decreases the variance and helps to avoid overfitting. It is usually applied to decision tree methods. Bagging is a special case of the model averaging approach. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4559b6",
   "metadata": {},
   "source": [
    "#### Q4. What is boosting?\n",
    "- Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series. Firstly, a model is built from the training data. Then the second model is built which tries to correct the errors present in the first model. This procedure is continued and models are added until either the complete training data set is predicted correctly or the maximum number of models is added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683237f5",
   "metadata": {},
   "source": [
    "#### Q5. What are the benefits of using ensemble techniques?\n",
    "- Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially for complex and noisy problems. They can also reduce the risk of overfitting and underfitting by balancing the trade-off between bias and variance, and by using different subsets and features of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80568e5",
   "metadata": {},
   "source": [
    "#### Q6. Are ensemble techniques always better than individual models?\n",
    "\n",
    "- Ensemble methods have higher predictive accuracy, compared to the individual models. 2. Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; different models can be combined to handle this type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05b5fc",
   "metadata": {},
   "source": [
    "#### Q7. How is the confidence interval calculated using bootstrap?\n",
    "\n",
    "- We want to obtain a 95% confidence interval (95% CI) around the our estimate of the mean difference. The 95% indicates that any such confidence interval will capture the population mean difference 95% of the time. That is to say, we can be 95% confident the interval contains the true mean of the population.It creates multiple resamples (with replacement) from a single set of observations, and computes the effect size of interest on each of these resamples. The bootstrap resamples of the effect size can then be used to determine the 95% CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a131e29",
   "metadata": {},
   "source": [
    "#### Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\n",
    " - Here are 3 quick steps that are involved in the Bootstrapping method -\n",
    "* Randomly choose a sample size.\n",
    "* Pick an observation from the training dataset in random order.\n",
    "* Combine this observation with the sample chosen earlier. \n",
    "\n",
    "For the samples that are chosen in the representative sample size, they are referred to as the ‘Bootstrapped samples’ or the bootstrap sample size. On the other hand, the samples that are not chosen are referred to as the ‘Out-of-the-bag’ samples that serve as the testing dataset. \n",
    "The bootstrapping method involves the bootstrapped samples or the training dataset being run through a machine learning model that is then tested using a new dataset - the Out-of-the-bag samples. \n",
    "The purpose of the method is to enable the model to predict results for the out-of-the-bag samples, which normally lead to a normal distribution or a Gaussian distribution. \n",
    "By using the replacement technique, the method follows the above-mentioned steps repeatedly (a minimum of 25 repetitions) in order to get better results. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729004c",
   "metadata": {},
   "source": [
    "#### Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e6d3be9",
   "metadata": {},
   "source": [
    "alpha = 0.95\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, numpy.percentile(stats, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, numpy.percentile(stats, p))\n",
    "print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e69aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
