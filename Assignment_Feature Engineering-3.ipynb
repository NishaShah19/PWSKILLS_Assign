{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe49ad66",
   "metadata": {},
   "source": [
    "#### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "Ans - MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.\n",
    "Min-Max scaling Transforms features by scaling each feature to a given range. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce55e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcbb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b2b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare\n",
       "0         0       3  22.0   7.2500\n",
       "1         1       1  38.0  71.2833\n",
       "2         1       3  26.0   7.9250\n",
       "3         1       1  35.0  53.1000\n",
       "4         0       3  35.0   8.0500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardization\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.read_csv('train.csv' , usecols = ['Pclass' , 'Age' , 'Fare' , 'Survived'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd93f0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass       Age      Fare\n",
       "0       0.0     1.0  0.271174  0.014151\n",
       "1       1.0     0.0  0.472229  0.139136\n",
       "2       1.0     1.0  0.321438  0.015469\n",
       "3       1.0     0.0  0.434531  0.103644\n",
       "4       0.0     1.0  0.434531  0.015713"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(min_max.fit_transform(df) , columns = df.columns)\n",
    "df_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c3f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec9d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([562., 170.,  67.,  39.,  15.,  16.,   2.,   0.,   9.,   2.,   6.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.]),\n",
       " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_minmax['Fare'] , bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d695f98",
   "metadata": {},
   "source": [
    "#### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "Ans - Scaling is done considering the whole feature vector to be of unit length. This usually means dividing each component by the Euclidean length of the vector (L2 Norm). In some applications (e.g., histogram features), it can be more practical to use the L1 norm of the feature vector.\n",
    "Like Min-Max Scaling, the Unit Vector technique produces values of range [0,1]. When dealing with features with hard boundaries, this is quite useful. For example, when dealing with image data, the colors can range from only 0 to 255. If we plot, then it would look as below for L1 and L2 norm, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc31b7",
   "metadata": {},
   "source": [
    "#### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "\n",
    "Ans - Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation that converts a set of correlated variables to a set of uncorrelated variables.PCA is the most widely used tool in exploratory data analysis and in machine learning for predictive models.Principal Component Analysis (PCA) is used to reduce the dimensionality of a data set by finding a new set of variables, smaller than the original set of variables, retaining most of the sampleâ€™s information, and useful for the regression and classification of data.\n",
    "Example - if you have a dataset of pictures of dogs, PCA could find the features that make a dog look like a dog, such as its shape, size, and color."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c990e8",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Ans - PCA can be used to identify the most important features in a dataset, which can be used to build predictive models.\n",
    "PCA calculates a new projection of the given data set representing one or more features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f91c4",
   "metadata": {},
   "source": [
    "#### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcde3ed",
   "metadata": {},
   "source": [
    "We can define min-max scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(min_max.fit_transform(df) , columns = df.columns)\n",
    "df_minmax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9001b3",
   "metadata": {},
   "source": [
    "#### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "Principal component analysis, or PCA, is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit vs fit_transform\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "pd.DataFrame(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3758a",
   "metadata": {},
   "source": [
    "#### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608c05d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 10, 15, 20]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "\n",
    "data = [0,5,10,15,20]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411a9e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.  5. 10. 15. 20.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23980/2285116519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print scaled features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    473\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    941\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.  5. 10. 15. 20.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(data)\n",
    "scaled_data=model.transform(data)\n",
    "\n",
    "# print scaled features\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e4a75",
   "metadata": {},
   "source": [
    "#### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d60bab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id;age;gender;height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0;18393;2;168;62.0;110;80;1;1;0;0;1;0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1;20228;1;156;85.0;140;90;3;1;0;0;1;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2;18857;1;165;64.0;130;70;3;1;0;0;0;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3;17623;2;169;82.0;150;100;1;1;0;0;1;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4;17474;1;156;56.0;100;60;1;1;0;0;0;0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id;age;gender;height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio\n",
       "0              0;18393;2;168;62.0;110;80;1;1;0;0;1;0                               \n",
       "1              1;20228;1;156;85.0;140;90;3;1;0;0;1;1                               \n",
       "2              2;18857;1;165;64.0;130;70;3;1;0;0;0;1                               \n",
       "3             3;17623;2;169;82.0;150;100;1;1;0;0;1;1                               \n",
       "4              4;17474;1;156;56.0;100;60;1;1;0;0;0;0                               "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_table('cardio_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993d697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
