{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51adc828",
   "metadata": {},
   "source": [
    "# Logistic Regression-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3ba0",
   "metadata": {},
   "source": [
    "#### Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "\n",
    "Ans -\n",
    "- GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8361bd",
   "metadata": {},
   "source": [
    "#### Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?\n",
    "\n",
    "Ans \n",
    "- Grid search -In Grid Search, we try every combination of a preset list of values of the hyper-parameters and evaluate the model for each combination. The pattern followed here is similar to the grid, where all the values are placed in the form of a matrix. Each set of parameters is taken into consideration and the accuracy is noted. Once all the combinations are evaluated, the model with the set of parameters which give the top accuracy is considered to be the best.\n",
    "\n",
    "- Random Search - Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. It tries random combinations of a range of values. To optimise with random search, the function is evaluated at some number of random configurations in the parameter space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add1bbd",
   "metadata": {},
   "source": [
    "#### Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "\n",
    "- Data leakage (or leakage) happens when the training data contains information about the target, but similar data won't be available when the model is used for prediction. This leads to high performance on the training dataset (and possibly even the validation data), but the model will perform badly in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff780574",
   "metadata": {},
   "source": [
    "#### Q4. How can you prevent data leakage when building a machine learning model?\n",
    "\n",
    "- To prevent data leakage, it is important to carefully select features, perform proper data splitting, and avoid target leakage during data preprocessing. Machine learning practitioners should also be aware of ethical considerations related to data leakage, such as the potential for discrimination or unfairness in the modelâ€™s predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf7919",
   "metadata": {},
   "source": [
    "#### Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\n",
    "Ans\n",
    "- A confusion matrix is a matrix that summarizes the performance of a machine learning model on a set of test data. It is often used to measure the performance of classification models, which aim to predict a categorical label for each input instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced67236",
   "metadata": {},
   "source": [
    "#### Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "- Precision: It can be defined as the number of correct outputs provided by the model or out of all positive classes that have predicted correctly by the model, how many of them were actually true.\n",
    "- Recall: It is defined as the out of total positive classes, how our model predicted correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e8b05",
   "metadata": {},
   "source": [
    "#### Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "\n",
    "Ans\n",
    "- TP: True Positive: The values which were actually positive and were predicted positive.\n",
    "- FP: False Positive: The values which were actually negative but falsely predicted as positive. ...\n",
    "- FN: False Negative: The values which were actually positive but falsely predicted as negative\n",
    "- TN: True Negative: The values which were actually negative and were predicted negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56038993",
   "metadata": {},
   "source": [
    "#### Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "\n",
    "1. Accuracy\n",
    "2. Precision = TP/(TP+FP)\n",
    "3. recall = TP/(TP+FN)\n",
    "4. f1-score = 2*(Precesion * Recall)/Precsion+recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee088e8c",
   "metadata": {},
   "source": [
    "#### Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "\n",
    "Ans\n",
    "-  Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier. To calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59725c",
   "metadata": {},
   "source": [
    "#### Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "\n",
    "Ans\n",
    "- The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing. Since it shows the errors in the model performance in the form of a matrix, hence also known as an error matrix.\n",
    "- It evaluates the performance of the classification models, when they make predictions on test data, and tells how good our classification model is.\n",
    "- It not only tells the error made by the classifiers but also the type of errors such as it is either type-I or type-II error.\n",
    "- With the help of the confusion matrix, we can calculate the different parameters for the model, such as accuracy, precision, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab6fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0042d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d7480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d01daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e322b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31491b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
