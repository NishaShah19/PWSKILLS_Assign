{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edc802c",
   "metadata": {},
   "source": [
    "# Logistic Regression-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44139071",
   "metadata": {},
   "source": [
    "#### Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate.\n",
    "\n",
    "Ans.\n",
    "- Linear regression -\n",
    "1. Linear Regression is one of the most simple Machine learning algorithm that comes under Supervised Learning technique and used for solving regression problems. \n",
    "2. It is used for predicting the continuous dependent variable with the help of independent variables.\n",
    "3. The goal of the Linear regression is to find the best fit line that can accurately predict the output for the continuous dependent variable.\n",
    "4. If single independent variable is used for prediction then it is called Simple Linear Regression and if there are more than two independent variables then such regression is called as Multiple Linear Regression\n",
    "5. The output for Linear regression should only be the continuous values such as price, age, salary, etc.\n",
    "\n",
    "- Logistic regression -\n",
    "1. Logistic regression is one of the most popular Machine learning algorithm that comes under Supervised Learning techniques.\n",
    "2. It can be used for Classification as well as for Regression problems, but mainly used for Classification problems.\n",
    "3. Logistic regression is used to predict the categorical dependent variable with the help of independent variables.\n",
    "4. The output of Logistic Regression problem can be only between the 0 and 1.\n",
    "5. In logistic regression, we pass the weighted sum of inputs through an activation function that can map values in between 0 and 1. Such activation function is known as sigmoid function and the curve obtained is called as sigmoid curve or S-curve.\n",
    "\n",
    "Let us consider a problem where we are given a dataset containing Height and Weight for a group of people. Our task is to predict the Weight for new entries in the Height column.\n",
    "Now suppose we have an additional field Obesity and we have to classify whether a person is obese or not depending on their provided height and weight. This is clearly a classification problem where we have to segregate the dataset into two classes (Obese and Not-Obese)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61d297",
   "metadata": {},
   "source": [
    "#### Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "\n",
    "Ans-\n",
    "- The cost function of logistic regression is a measure of how well the model is predicting the target variable. It is defined as:\n",
    "\n",
    "J(w) = -1/m * [ sum(y_i*log(h(x_i)) + (1-y_i)*log(1-h(x_i))) ]\n",
    "The cost function measures the difference between the predicted probabilities and the actual values of the target variable. The closer the predicted probabilities are to the actual values, the lower the cost function.\n",
    "- Cost function also plays a crucial role in understanding that how well your model estimates the relationship between the input and output parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43869ae",
   "metadata": {},
   "source": [
    "#### Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "\n",
    "Ans \n",
    "- Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables\n",
    "- Regularization adds penalties to the parameters and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation. Thus, if the coefficient inflates, the cost function will increase. And Linear regression model will try to optimize the coefficient in order to minimize the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badefb1",
   "metadata": {},
   "source": [
    "#### Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
    "\n",
    "- ROC or Receiver Operating Characteristic plot is used to visualise the performance of a binary classifier. It gives us the trade-off between the True Positive Rate (TPR) and the False Positive Rate (FPR) at different classification thresholds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eaae3e",
   "metadata": {},
   "source": [
    "#### Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
    "\n",
    "Ans\n",
    "- L1 regularization - It is a method for penalizing the magnitude of the coefficients in the logistic regression model. The goal is to encourage the model to select only the most important features, while setting the coefficients of irrelevant features to zero. \n",
    "- Correlation-Based Feature Selection - Correlation-based feature selection involves selecting features that are highly correlated with the outcome variable. The idea is that if a feature is highly correlated with the outcome, it is likely to be a good predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a4808",
   "metadata": {},
   "source": [
    "#### Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
    "\n",
    "Ans\n",
    "- Scikit-Learn provides a convenient way to assign class weights using the class_weight parameter in the LogisticRegression class. The class_weight parameter can be set to either ‘balanced’ or a dictionary of class weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf383421",
   "metadata": {},
   "source": [
    "#### Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example, what can be done if there is multicollinearity among the independent variables?\n",
    "\n",
    "Ans\n",
    "- Logistic Regression requires moderate or no multicollinearity between independent variables. This means if two independent variables have a high correlation, only one of them should be used. Repetition of information could lead to wrong training of parameters (weights) during minimizing the cost function.\n",
    "- If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting.\n",
    "- Overfitting: Logistic regression is prone to overfitting, especially if the model is too complex or if there is a small amount of data. Overfitting occurs when the model becomes too good at fitting the training data and performs poorly on new, unseen data.\n",
    "\n",
    "- Multicollinearity: Logistic regression assumes that the input variables are independent of each other. However, in practice, it is often the case that input variables are correlated, which can lead to multicollinearity and unstable model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda4dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
