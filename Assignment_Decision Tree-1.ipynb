{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45d3b3d",
   "metadata": {},
   "source": [
    "# Decision Tree-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3b74f",
   "metadata": {},
   "source": [
    "#### Q1. Describe the decision tree classifier algorithm and how it works to make predictions.\n",
    "\n",
    "- Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and what the corresponding output is in the training data) where the data is continuously split according to a certain parameter. The tree can be explained by two entities, namely decision nodes and leaves. The leaves are the decisions or the final outcomes. And the decision nodes are where the data is split.\n",
    "- The decision tree operates by analyzing the data set to predict its classification. It commences from the tree’s root node, where the algorithm views the value of the root attribute compared to the attribute of the record in the actual data set. Based on the comparison, it proceeds to follow the branch and move to the next node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f025625",
   "metadata": {},
   "source": [
    "#### Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.\n",
    "\n",
    "- Step-1: Begin the tree with the root node, says S, which contains the complete dataset.\n",
    "- Step-2: Find the best attribute in the dataset using Attribute Selection Measure (ASM).\n",
    "- Step-3: Divide the S into subsets that contains possible values for the best attributes.\n",
    "- Step-4: Generate the decision tree node, which contains the best attribute.\n",
    "- Step-5: Recursively make new decision trees using the subsets of the dataset created in step -3. Continue this process until a stage is reached where you cannot further classify the nodes and called the final node as a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8d132",
   "metadata": {},
   "source": [
    "#### Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.\n",
    "\n",
    "- Suppose there is a candidate who has a job offer and wants to decide whether he should accept the offer or Not. So, to solve this problem, the decision tree starts with the root node (Salary attribute by ASM). The root node splits further into the next decision node (distance from the office) and one leaf node based on the corresponding labels. The next decision node further gets split into one decision node (Cab facility) and one leaf node. Finally, the decision node splits into two leaf nodes (Accepted offers and Declined offer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654be3ed",
   "metadata": {},
   "source": [
    "#### Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.\n",
    "\n",
    "- Entropy (ID3)\n",
    "Entropy is a measure of randomness. In other words, its a measure of unpredictability. We will take a moment here to give entropy in case of a binary event(like the coin toss, where output can be either of the two events, head or tail)\n",
    "\n",
    "- Information Gain (ID3)\n",
    "The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about finding the attribute that returns the highest information gain (i.e., the most homogeneous branches).\n",
    "\n",
    "- Gini Impurity (CART).\n",
    "The Gini Index is calculated by subtracting the sum of the squared probabilities of each class from one. It favors larger partitions. Information Gain multiplies the probability of the class times the log (base=2) of that class probability. Information Gain favors smaller partitions with many distinct values. Ultimately, you have to experiment with your data and the splitting criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7eebb8",
   "metadata": {},
   "source": [
    "#### Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.\n",
    "\n",
    "- The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing. Since it shows the errors in the model performance in the form of a matrix, hence also known as an error matrix. \n",
    "A confusion matrix is a technique for summarizing the performance of a classification algorithm.\n",
    "\n",
    "Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two classes in your dataset.\n",
    "\n",
    "Calculating a confusion matrix can give you a better idea of what your classification model is getting right and what types of errors it is making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652822c0",
   "metadata": {},
   "source": [
    "#### Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.\n",
    "\n",
    "- A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.\n",
    "\n",
    "True Positives (TP): when the actual value is Positive and predicted is also Positive.\n",
    "True negatives (TN): when the actual value is Negative and prediction is also Negative.\n",
    "False positives (FP): When the actual is negative but prediction is Positive. Also known as the Type 1 error\n",
    "False negatives (FN): When the actual is Positive but the prediction is Negative. Also known as the Type 2 error\n",
    "\n",
    "- Precision: It is a measure of correctness that is achieved in true prediction. In simple words, it tells us how many predictions are actually positive out of all the total positive predicted.\n",
    "\n",
    "- Recall: It is a measure of actual observations which are predicted correctly, i.e. how many observations of positive class are actually predicted as positive. It is also known as Sensitivity. Recall is a valid choice of evaluation metric when we want to capture as many positives as possible.\n",
    "\n",
    "- F1-Score : The F1 score is a number between 0 and 1 and is the harmonic mean of precision and recall. We use harmonic mean because it is not sensitive to extremely large values, unlike simple averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ade4a7",
   "metadata": {},
   "source": [
    "#### Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.\n",
    "\n",
    "- We have different evaluation metrics for a different set of machine learning algorithms. For evaluating classification models, we use classification metrics and for evaluating regression models, we use regression metrics. In this article, I’ll talk about only classification metrics.\n",
    "\n",
    "Evaluation metrics can help you assess your model’s performance, monitor your ML system in production, and control your model to fit your business needs.\n",
    "\n",
    "Our goal is to create and select a model which gives high accuracy on out-of-sample data. It’s very crucial to use multiple evaluation metrics to evaluate your model because a model may perform well using one measurement from one evaluation metric while may perform poorly using another measurement from another evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf04756",
   "metadata": {},
   "source": [
    "#### Q8. Provide an example of a classification problem where precision is the most important metric, and explain why.\n",
    "\n",
    "- Precision for Multi-Class Classification\n",
    "For example, we may have an imbalanced multiclass classification problem where the majority class is the negative class, but there are two positive minority classes: class 1 and class 2. Precision can quantify the ratio of correct predictions across both positive classes.\n",
    "- Email Spam detection:This is one of the example where Precision is more important than Recall. Quick Recap: Precision: This tells when you predict something positive, how many times they were actually positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2c16c",
   "metadata": {},
   "source": [
    "#### Q9. Provide an example of a classification problem where recall is the most important metric, and explain why.\n",
    "\n",
    "- Recall is very used when you have to correctly classify some event that has already occurred. For example, fraud detection models must have a high recall in order to detect frauds properly. In such situations, we don’t care about the real 0s, because we are interested only in spotting the real 1s as often as possible. So, we’re working with the second row of the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
